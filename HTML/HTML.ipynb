{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RQG78HkO-OqG"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "import numpy as np\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2iofu1jp-OqL"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, Flatten\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p-9GwpEj-OqM"
      },
      "outputs": [],
      "source": [
        "# Load the images and preprocess them for inception-resnet\n",
        "images = []\n",
        "all_filenames = listdir('images/')\n",
        "all_filenames.sort()\n",
        "for filename in all_filenames:\n",
        "    images.append(img_to_array(load_img('images/'+filename, target_size=(299, 299))))\n",
        "images = np.array(images, dtype=float)\n",
        "images = preprocess_input(images)\n",
        "\n",
        "# Run the images through inception-resnet and extract the features without the classification layer\n",
        "IR2 = InceptionResNetV2(weights='imagenet', include_top=False)\n",
        "features = IR2.predict(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cCPUppEM-OqN"
      },
      "outputs": [],
      "source": [
        "# We will cap each input sequence to 100 tokens\n",
        "max_caption_len = 100\n",
        "# Initialize the function that will create our vocabulary \n",
        "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
        "\n",
        "# Read a document and return a string\n",
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Load all the HTML files\n",
        "X = []\n",
        "all_filenames = listdir('html/')\n",
        "all_filenames.sort()\n",
        "for filename in all_filenames:\n",
        "    X.append(load_doc('html/'+filename))\n",
        "\n",
        "# Create the vocabulary from the html files\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "# Add +1 to leave space for empty words\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "# Translate each word in text file to the matching vocabulary index\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "# The longest HTML file\n",
        "max_length = max(len(s) for s in sequences)\n",
        "\n",
        "# Intialize our final input to the model\n",
        "X, y, image_data = list(), list(), list()\n",
        "for img_no, seq in enumerate(sequences):\n",
        "    for i in range(1, len(seq)):\n",
        "        # Add the entire sequence to the input and only keep the next word for the output\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "        # If the sentence is shorter than max_length, fill it up with empty words\n",
        "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "        # Map the output to one-hot encoding\n",
        "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "        # Add and image corresponding to the HTML file\n",
        "        image_data.append(features[img_no])\n",
        "        # Cut the input sentence to 100 tokens, and add it to the input data\n",
        "        X.append(in_seq[-100:])\n",
        "        y.append(out_seq)\n",
        "\n",
        "X, y, image_data = np.array(X), np.array(y), np.array(image_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pv0hAd6Z-OqP"
      },
      "outputs": [],
      "source": [
        "# Create the encoder\n",
        "image_features = Input(shape=(8, 8, 1536,))\n",
        "image_flat = Flatten()(image_features)\n",
        "image_flat = Dense(128, activation='relu')(image_flat)\n",
        "ir2_out = RepeatVector(max_caption_len)(image_flat)\n",
        "\n",
        "language_input = Input(shape=(max_caption_len,))\n",
        "language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)\n",
        "language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "language_model = LSTM(256, return_sequences=True)(language_model)\n",
        "language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)\n",
        "\n",
        "# Create the decoder\n",
        "decoder = concatenate([ir2_out, language_model])\n",
        "decoder = LSTM(512, return_sequences=False)(decoder)\n",
        "decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "# Compile the model\n",
        "model = Model(inputs=[image_features, language_input], outputs=decoder_output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        if(logs['loss'] < 0.01):   \n",
        "          print('reached threshold')  \n",
        "          self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "BEaoluWtHiZl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wNjuQ_-2-Oqa"
      },
      "outputs": [],
      "source": [
        "# Train the neural network\n",
        "#model.fit([image_data, X], y, batch_size=64, shuffle=True, epochs=10000, callbacks = [callbacks])\n",
        "\n",
        "#loading weights\n",
        "model.load_weights('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "92kFGBSg-Oqb"
      },
      "outputs": [],
      "source": [
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lX_XyMy7-Oqb"
      },
      "outputs": [],
      "source": [
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    # seed the generation process\n",
        "    in_text = 'START'\n",
        "    # iterate over the whole length of the sequence\n",
        "    for i in range(900):\n",
        "        # integer encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0][-100:]\n",
        "        # pad input\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # predict next word\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        # convert probability to integer\n",
        "        yhat = np.argmax(yhat)\n",
        "        # map integer to word\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        # stop if we cannot map the word\n",
        "        if word is None:\n",
        "            break\n",
        "        # append as input for generating the next word\n",
        "        in_text += ' ' + word\n",
        "        # Print the prediction\n",
        "        print(' ' + word, end='')\n",
        "        # stop if we predict the end of the sequence\n",
        "        if word == 'END':\n",
        "            break\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnn_JN3p-Oqd",
        "outputId": "2ac3e920-c3ab-4564-a423-b374a0b7d12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " <!DOCTYPE html>\n",
            "<html lang=\"en\" dir=\"ltr\">\n",
            "<head>\n",
            "<title>Basic 87</title>\n",
            "<meta charset=\"iso-8859-1\">\n",
            "<link rel=\"stylesheet\" href=\"styles/layout.css\" type=\"text/css\">\n",
            "<!--[if lt IE 9]><script src=\"scripts/html5shiv.js\"></script><![endif]-->\n",
            "</head>\n",
            "<body>\n",
            "<div class=\"wrapper row1\">\n",
            " <header id=\"header\" class=\"clear\">\n",
            " <div id=\"hgroup\">\n",
            " <h1><a href=\"#\">Basic 87</a></h1>\n",
            " <h2>Free HTML5 Website Template</h2>\n",
            " </div>\n",
            " <nav>\n",
            " <ul>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li><a href=\"#\">Text Link</a></li>\n",
            " <li class=\"last\"><a href=\"#\">Text Link</a></li>\n",
            " </ul>\n",
            " </nav>\n",
            " </header>\n",
            "</div>\n",
            "<!-- content -->\n",
            "<div class=\"wrapper row2\">\n",
            " <div id=\"container\" class=\"clear\">\n",
            " <!-- content body -->\n",
            " <div id=\"homepage\">\n",
            " <!-- One Quarter -->\n",
            " <section id=\"latest\" class=\"clear\">\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x315.gif\" width=\"215\" height=\"315\" alt=\"\">\n",
            " <figcaption>Image Caption Here</figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x315.gif\" width=\"215\" height=\"315\" alt=\"\">\n",
            " <figcaption>Image Caption Here</figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter\">\n",
            " <figure><img src=\"images/demo/215x315.gif\" width=\"215\" height=\"315\" alt=\"\">\n",
            " <figcaption>Image Caption Here</figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " <article class=\"one_quarter lastbox\">\n",
            " <figure><img src=\"images/demo/215x315.gif\" width=\"215\" height=\"315\" alt=\"\">\n",
            " <figcaption>Image Caption Here</figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " </section>\n",
            " <!-- / One Quarter -->\n",
            " <section id=\"shout\">\n",
            " <p>Vestibulumaccumsan egestibulum eu justo convallis augue estas aenean elit intesque sed. Facilispede estibulum nulla orna nisl velit elit ac aliquat non tincidunt. Namjusto cras urna urnaretra lor urna neque sed quis orci nulla laoremut vitae doloreet condimentumst.</p>\n",
            " </section>\n",
            " </div>\n",
            " <!-- main content -->\n",
            " <div id=\"content\">\n",
            " <section id=\"services\" class=\"last clear\">\n",
            " <ul>\n",
            " <li>\n",
            " <article class=\"clear\">\n",
            " <figure><img src=\"images/demo/180x150.gif\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis leo nibh</h2>\n",
            " <p>This is a W3C compliant free website template from <a href=\"http://www.os-templates.com/\" title=\"Free Website Templates\">OS Templates</a>. For full terms of use of this template please read our <a href=\"http://www.os-templates.com/template-terms\">website template licence</a>.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " </li>\n",
            " <li class=\"last\">\n",
            " <article class=\"clear\">\n",
            " <figure><img src=\"images/demo/180x150.gif\" alt=\"\">\n",
            " <figcaption>\n",
            " <h2>Indonectetus facilis leo nibh</h2>\n",
            " <p>You can use and modify the template for both personal and commercial use. You must keep all copyright information and credit links in the template and associated files. For more HTML5 templates visit <a href=\"http://www.os-templates.com/\">free website templates</a>.</p>\n",
            " <footer class=\"more\"><a href=\"#\">Read More &raquo;</a></footer>\n",
            " </figcaption>\n",
            " </figure>\n",
            " </article>\n",
            " </li>\n",
            " </ul>\n",
            " </section>\n",
            " </div>\n",
            " <!-- right column -->\n",
            " <aside id=\"right_column\">\n",
            " <h2 class=\"title\">Categories</h2>\n",
            " <nav>\n",
            " <ul>\n",
            " <li><a href=\"#\">Free Website Templates</a></li>\n",
            " <li><a href=\"#\">Free CSS Templates</a></li>\n",
            " <li><a href=\"#\">Free XHTML Templates</a></li>\n",
            " <li><a href=\"#\">Free Web Templates</a></li>\n",
            " <li><a href=\"#\">Free Website Layouts</a></li>\n",
            " <li><a href=\"#\">Free HTML 5 Templates</a></li>\n",
            " <li><a href=\"#\">Free Webdesign Templates</a></li>\n",
            " <li><a href=\"#\">Free FireWorks Templates</a></li>\n",
            " <li><a href=\"#\">Free PNG Templates</a></li>\n",
            " <li class=\"last\"><a href=\"#\">Free Website Themes</a></li>\n",
            " </ul>\n",
            " </nav>\n",
            " <!-- /nav -->\n",
            " </aside>\n",
            " <!-- / content body -->\n",
            " </div>\n",
            "</div>\n",
            "<!-- Footer -->\n",
            "<div class=\"wrapper row3\">\n",
            " <footer id=\"footer\" class=\"clear\">\n",
            " <p class=\"fl_left\">Copyright &copy; 2012 - All Rights Reserved - <a href=\"#\">Domain Name</a></p>\n",
            " <p class=\"fl_right\">Template by <a href=\"http://www.os-templates.com/\" title=\"Free Website Templates\">OS Templates</a></p>\n",
            " </footer>\n",
            "</div>\n",
            "</body>\n",
            "</html> END"
          ]
        }
      ],
      "source": [
        "# Load and image, preprocess it for IR2, extract features and generate the HTML\n",
        "test_image = img_to_array(load_img('images/87.jpg', target_size=(299, 299)))\n",
        "test_image = np.array(test_image, dtype=float)\n",
        "test_image = preprocess_input(test_image)\n",
        "test_features = IR2.predict(np.array([test_image]))\n",
        "generate_desc(model, tokenizer, np.array(test_features), 100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "HTML.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}